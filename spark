pyspark


from pyspark.sql  import HiveContext
sqlContext = HiveContext(sc)
depts = sqlContext.sql("select * from categories")


for rec in depts.collect():
   print(rec)
   
   
   
  create file saveFile.py
  
  from pyspark import SparkContext, SparkConf

conf = SparkConf().setAppName("pyspark")
sc = SparkContext(conf=conf)
dataRDD = sc.textFile("/user/jagadeesh427/sqoop_import/departments")
for line in dataRDD.collect():
   print(line)
dataRDD.saveAsTextFile("/user/jagadeesh427/pyspark/departments")


spark-submit --master yarn or local saveFile.py

